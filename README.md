# Factuality versus Fairness: Evaluating Bias in Knowledge-enhanced LMs

This repository contains a collection of intrinsic and downstream tasks to evaluate biases in 
knowledge-enhanced language models (LMs). 

## Evaluation results
TBD


## Replicate results
### Setup
* Download the models + sources by running the bash script `clone_model_repos.sh`
* TBD: requirements installation
* TBD: download trained downstream task classifiers

### Configurations
TBD

### Running the evaluations
TBD